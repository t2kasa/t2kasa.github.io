---
title:  "SVM (2)"
permalink: 2018-12-17-svm-part2.html
sidebar: blog_sidebar
tags: [SVM]
---

\begin{align}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\bxi}{\boldsymbol{\xi}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}} \nonumber
\end{align}

[前回](2018-12-16-svm-part1.html)ではハードマージンかつ線形のSVMについて書いた．今回は**ソフトマージン**の場合について書こう．いきなりだが，ソフトマージンSVMについてはブログとは別の[こちらのページ](soft-margin-svm.html)に書いてあるので，そちらを見て頂きたい．

### CVXOPTによる実装例

凸最適化のためのパッケージ[CVXOPT](https://github.com/cvxopt/cvxopt)で$\balpha$を求めてみる．詳しくは上述のページを見てもらえれば分かるが，制約条件以外はハードマージンSVMと同様である．

<script src="https://gist.github.com/t2kasa/fc209609555f30d0f939e91141f2aaa1.js"></script>

![soft-margin-linear-svm-example](images/figs/2018-12-17-svm-part2/soft-margin-linear-svm-example.png)
